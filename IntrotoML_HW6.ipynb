{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 6: Dimensionality Reduction (100 points)\n",
    "\n",
    "In this homework, you will be implementing Principal Component Analysis (PCA) and K-means clustering from scratch in python using NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "\n",
    "Load train and test data for the Fashion MNIST dataset using PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dimension  = 28*28   # images are 28x28 pixels\n",
    "num_classes = 10      # there are 10 classes\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(\n",
    "    root=\"data_fashion\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_dataset = datasets.FashionMNIST(\n",
    "    root=\"data_fashion\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A: Subsampling from the dataset\n",
    "\n",
    "In this part, you must subsample the train and test set such both contain 1000 images, with 100 images from each of the 10 classes. Also store the labels for each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_per_class = 100\n",
    "\n",
    "# Create a new dataset with only 100 images per class and with a total of 1000 images\n",
    "def create_subset(dataset, images_per_class):\n",
    "    \"\"\"\n",
    "    Create a dataset with only a given number of images per class.\n",
    "\n",
    "    Args:\n",
    "        dataset: The original dataset\n",
    "        images_per_class: The number of images per class to keep\n",
    "    \n",
    "    Returns:\n",
    "        images: A numpy array of shape (num_classes * images_per_class, data_dimension)\n",
    "        labels: A numpy array of shape (num_classes * images_per_class,)\n",
    "    \"\"\"\n",
    "    images, labels = [], []\n",
    "    \n",
    "    # WRITE YOUR CODE HERE\n",
    "    \n",
    "    \n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Train and test data\n",
    "train_images, train_labels = create_subset(train_dataset, images_per_class)\n",
    "test_images, test_labels = create_subset(test_dataset, images_per_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot grid of images\n",
    "\n",
    "You must complete the `plot_grid` function defined below. A sample image of the plot has been provided with the homework (see `sample_output_grid.png`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grid(images, labels, num_classes, num_images_per_class):\n",
    "    \"\"\"\n",
    "    Plot a grid of images of shape num_classes x images_per_class. Each row must \n",
    "    contain the images belonging to an unique class.\n",
    "\n",
    "    Args:\n",
    "        images: A numpy array of shape (num_classes * images_per_class, data_dimension)\n",
    "        labels: A numpy array of shape (num_classes * images_per_class,)\n",
    "        num_classes: The number of classes\n",
    "        num_images_per_class: The number of images per class to be displayed\n",
    "    \n",
    "    Hint: Use plt.subplot to plot the images in a grid.\n",
    "    \"\"\"\n",
    "    # WRITE YOUR CODE HERE\n",
    "    \n",
    "    \n",
    "plot_grid(train_images, train_labels, num_classes, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B: Principal Component Analysis (PCA)\n",
    "\n",
    "Perform principal component analysis (PCA) on the train dataset to reduce the data dimension from `784` to `100`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA(X , num_components):\n",
    "    \"\"\"\n",
    "    Function to perform PCA on the dataset X.\n",
    "\n",
    "    Args:\n",
    "        X: A numpy array of shape (num_samples, data_dimension)\n",
    "        num_components: The number of principal components to keep\n",
    "\n",
    "    Returns:\n",
    "        X_reduced: A numpy array of shape (num_samples, num_components). The represents the reduced data.\n",
    "        X_reconstructed: A numpy array of shape (num_samples, data_dimension). The represents the reconstructed data from the reduced data.\n",
    "    \"\"\"\n",
    "    # WRITE YOUR CODE HERE\n",
    "    X_reduced = None\n",
    "    X_reconstructed = None\n",
    "     \n",
    "    return X_reduced, X_reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_dimension = 100\n",
    "train_images_pca, reconstruction = PCA(train_images, pca_dimension)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the original images\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.imshow(train_images[i].reshape(28, 28), cmap='gray')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the reconstructed images\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.imshow(reconstruction[i].reshape(28, 28), cmap='gray')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reconstructed images must look similar to the original input images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part C: KMeans Clustering\n",
    "\n",
    "In this part, you will be clustering the train images that had been reduced to 100 dimensions using PCA into `10 clusters`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean(point, data):\n",
    "    \"\"\"\n",
    "    Euclidean distance between point & data.\n",
    "    Point has dimensions (m,), data has dimensions (n,m), and output will be of size (n,).\n",
    "\n",
    "    Args:\n",
    "        point: A numpy array of shape (m,)\n",
    "        data: A numpy array of shape (n,m)\n",
    "\n",
    "    Returns:\n",
    "        A numpy array of shape (n,) containing the euclidean distance between point and each row of data.\n",
    "    \"\"\"\n",
    "    # WRITE YOUR CODE HERE\n",
    "    \n",
    "    return None\n",
    "\n",
    "class KMeans:\n",
    "    \"\"\"\n",
    "    Class to perform K-Means clustering.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_clusters=8, max_iter=300):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            n_clusters: The number of clusters\n",
    "            max_iter: The maximum number of iterations to run the algorithm for\n",
    "        \n",
    "        \"\"\"\n",
    "        self.n_clusters = n_clusters\n",
    "        self.max_iter = max_iter\n",
    "    \n",
    "    def init_centroids(self, X):\n",
    "        \"\"\"\n",
    "        Initialize the centroids by randomly sampling from the dataset. Store the computed\n",
    "        centroids in self.centroids.\n",
    "\n",
    "        Args:\n",
    "            X: A numpy array of shape (num_samples, data_dimension)\n",
    "        \n",
    "        Hint: Initialize the centroids such that when a random datapoint is selected as the first, \n",
    "              the rest are initialized w/ probabilities proportional to their distances to the first.\n",
    "              You may use argument `p` in np.random.choice to do this.\n",
    "        \"\"\"\n",
    "        # WRITE YOUR CODE HERE\n",
    "\n",
    "    def fit(self, X_train):\n",
    "        \"\"\"\n",
    "        Train the K-Means model on the dataset X_train.\n",
    "\n",
    "        Args:\n",
    "            X_train: A numpy array of shape (num_samples, data_dimension)\n",
    "\n",
    "        Hint: \n",
    "            (1) Use the euclidean function defined above. \n",
    "            (2) Run the algorithm for a maximum of self.max_iter iterations.\n",
    "            (3) Initialize the centroids before running the clustering algorithm.\n",
    "        \"\"\"\n",
    "        # WRITE YOUR CODE HERE\n",
    "\n",
    "\n",
    "    def evaluate(self, X):\n",
    "        \"\"\"\n",
    "        Function to evaluate the K-Means model on the dataset X.\n",
    "\n",
    "        Args:\n",
    "            X: A numpy array of shape (num_samples, data_dimension)\n",
    "        \n",
    "        Returns:\n",
    "            centroids: A numpy array of shape (n_clusters, data_dimension) containing the centroids of the clusters.\n",
    "            centroid_idxs: A numpy array of shape (num_samples,) containing the cluster labels for each sample in X.\n",
    "        \"\"\"\n",
    "        centroids, centroid_idxs = [], []\n",
    "\n",
    "        # WRITE YOUR CODE HERE\n",
    "\n",
    "        \n",
    "        return centroids, centroid_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=10)\n",
    "kmeans.fit(train_images_pca)\n",
    "\n",
    "# View results\n",
    "class_centers, classification = kmeans.evaluate(train_images_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot mean image for each cluster\n",
    "\n",
    "The KMeans clustering algorithm provides you with 10 clusters, with each cluster containing a set of images. In this part, you must compute the mean image for each cluster and plot it as a grid with 10 images such that each image corresponds to the mean image of a cluster. By mean image of a cluster, we imply the mean of the images contained in the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot grid of cluster images from each class\n",
    "\n",
    "# WRITE YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot grid containing 10 images for each cluster\n",
    "\n",
    "In this part, you must plot a grid of images of size `number of cluster x 10` with each row corresponding to a unique cluster and all columns corresponding to a row comprise 10 samples from the cluster that the row represents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 10 images from each cluster for each class\n",
    "\n",
    "# WRITE YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Credit: k-Nearest Neighbor (KNN) classification (25 points)\n",
    "\n",
    "In this section, you are supposed to perform k-Nearest Neighbor classification on the test data and find the optimal value of `k` for which the model outputs the highest classification accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common(lst):\n",
    "    '''Returns the most common element in a list. If there is a tie, returns the \n",
    "    element occuring first in the list.'''\n",
    "    # WRITE YOUR CODE HERE\n",
    "\n",
    "    return None\n",
    "\n",
    "class KNearestNeighborsClassifier():\n",
    "    \"\"\"\n",
    "    Class to perform K-Nearest Neighbors classification.\n",
    "    \"\"\"\n",
    "    def __init__(self, k=5, dist_metric=euclidean):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            k: The number of nearest neighbors to use for classification\n",
    "            dist_metric: The distance metric to use for classification. (Default: euclidean)\n",
    "        \"\"\"\n",
    "        self.k = k\n",
    "        self.dist_metric = dist_metric\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        \"\"\"\n",
    "        Function to train the K-Nearest Neighbors classifier on the train dataset.\n",
    "\n",
    "        Args:\n",
    "            X_train: A numpy array of shape (num_samples, data_dimension) containing the training data.\n",
    "            y_train: A numpy array of shape (num_samples,) containing the training labels.\n",
    "        \"\"\"\n",
    "        # WRITE YOUR CODE HERE\n",
    "       \n",
    "\n",
    "    def predict(self, X_test):\n",
    "        \"\"\"\n",
    "        Predict the labels for the test dataset.\n",
    "\n",
    "        Args:\n",
    "            X_test: A numpy array of shape (num_samples, data_dimension) containing the test data.\n",
    "\n",
    "        Returns:\n",
    "            y_pred: A numpy array of shape (num_samples,) containing the predicted labels for the test data.\n",
    "\n",
    "        Hint: Use the self.dist_metric function to compute the distance between the test data and the training data.\n",
    "              For each sample, choose the most common label among the k nearest neighbors.\n",
    "        \"\"\"\n",
    "        # WRITE YOUR CODE HERE\n",
    "\n",
    "        return None\n",
    "    \n",
    "    def evaluate(self, X_test, y_test):\n",
    "        \"\"\"\n",
    "        Evaluate the K-Nearest Neighbors classifier on the test dataset.\n",
    "\n",
    "        Args:\n",
    "            X_test: A numpy array of shape (num_samples, data_dimension) containing the test data.\n",
    "            y_test: A numpy array of shape (num_samples,) containing the test labels.\n",
    "\n",
    "        Returns:\n",
    "            accuracy: A float value between 0 and 1 representing the accuracy of the classifier.\n",
    "        \"\"\"\n",
    "        # WRITE YOUR CODE HERE\n",
    "        \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate KNN classifier for k varying from 1 to 30 and plot the accuracy\n",
    "accuracies = []\n",
    "ks = range(1, 30)\n",
    "for k in ks:\n",
    "    knn = KNearestNeighborsClassifier(k=k)\n",
    "    knn.fit(train_images, train_labels)\n",
    "    accuracy = knn.evaluate(test_images, test_labels)\n",
    "    accuracies.append(accuracy)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(ks, accuracies)\n",
    "ax.set(xlabel=\"k\",\n",
    "       ylabel=\"Accuracy\",\n",
    "       title=\"Performance of knn\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report the k for which you get the highest accuracy on the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write your answer here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('mlug')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fc6f77fc95e5420108aa348103e4498d1d0de016cf7e1fd7da540445454c305d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
